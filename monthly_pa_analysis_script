# Name: Global coverage analysis script
# Version: 1.9
# Created on: 01/07/2019
# Last updated on: 15/11/2019
# Created by: Ed Lewis (edward.lewis@unep-wcmc.org)
# Description: A script based on an Esri model to calculate PA coverage globally and nationally as well as calculating national
# PAME statistics.

#--------------------------------------------------------------------------------------------------------------------------
### Stage 0: Define script inputs ###

# import arcpy module
import arcpy
import os
import time
from arcpy import env

#start the stopwatch
start = time.clock()

# enable the overwriting of outputs
arcpy.env.overwriteOutput = True

# define workspace to house all outputs from the script we want to keep
arcpy.env.workspace = r"C:\Users\EdwardL\Documents\ArcGIS\Default.gdb"
workspace = env.workspace

# define the scratch workspace for outputs we dont want to keep
arcpy.env.scratchWorkspace = r"C:\Users\EdwardL\Documents\ArcGIS\Modelbuilder_Primary.gdb"

# define the projection files used to define outputs/workspaces
in_mollweideprj = r"C:\Users\EdwardL\Desktop\Temp_Files Of_Interest\moll_projection.prj"

# define the scripts inputs
# WDPA Public points
in_points = r"E:\_Useful_Datasets_\Model_test_country\CHL_Test.gdb\CHL_Test_Pnt"
# WDPA Public polygons
in_polygons = r"E:\_Useful_Datasets_\Model_test_country\BLM_model_testing.gdb\BLM_model_testing_subset"
# Basemap_spatial
in_basemap_spat = r"E:\_Useful_Datasets_\WVS_Jan_16\SDG_Basemap.gdb\EEZv8_WVS_DIS_V3_ALL_final_v7dis_with_SDG_regions_for_models"
# Basemap_tabular
in_basemap_tab = r"E:\_Useful_Datasets_\WVS_Jan_16\SDG_Basemap.gdb\EEZv8_WVS_DIS_V3_ALL_final_v7dis_with_SDG_regions_for_models_tabular"
# PAME sites
in_pame_sites = r"C:\Users\EdwardL\Documents\ArcGIS\Restricted_Data.gdb\PAME_Sites"

# define the scripts restricted inputs - only accessible for UNEP-WCMC
# restricted CHN points
in_restrict_chn_pnt = r"E:\_Useful_Datasets_\Model_test_country\Restricted_subset_model_testing.gdb\CHN_restricted_testing_for_model_pnt"
# restricted CHN polygons
in_restrict_chn_poly = r"E:\_Useful_Datasets_\Model_test_country\Restricted_subset_model_testing.gdb\CHN_restricted_testing_for_model"
# restricted SHN polygons
in_restrict_shn_poly = r"E:\_Useful_Datasets_\Model_test_country\Restricted_subset_model_testing.gdb\EST_restricted_testing_for_model"
# restricted EST polygons
in_restrict_est_poly = r"E:\_Useful_Datasets_\Model_test_country\Restricted_subset_model_testing.gdb\SHN_restricted_testing_for_model"

# define the merge outputs
out_all_points = "all_wdpa_points"
out_all_polygons = "all_wdpa_polygons"



#--------------------------------------------------------------------------------------------------------------------------
# Stage 1: Global analysis

print ("Stage 1/3: Global analysis")

# combine the point inputs together
arcpy.Merge_management([in_points,in_restrict_chn_pnt], out_all_points)
# combine the polygon inputs together
arcpy.Merge_management([in_polygons, in_restrict_chn_poly, in_restrict_shn_poly, in_restrict_est_poly], out_all_polygons)

# repair geometries for newly merged files
arcpy.RepairGeometry_management("all_wdpa_points","DELETE_NULL","OGC")
arcpy.RepairGeometry_management("all_wdpa_polygons","DELETE_NULL","OGC")

# remove the sites that have an uncertain status or have potentially very innacruate areas
arcpy.Select_analysis("all_wdpa_points", "all_wdpa_points_select","STATUS in ('Adopted', 'Designated', 'Inscribed') AND NOT DESIG_ENG = 'UNESCO-MAB Biosphere Reserve'")
arcpy.Select_analysis("all_wdpa_polygons", "all_wdpa_polygons_select","STATUS in ('Adopted', 'Designated', 'Inscribed') AND NOT DESIG_ENG = 'UNESCO-MAB Biosphere Reserve'")

# convert the point selection into a polygon by buffering by the REP_AREA
arcpy.AddField_management("all_wdpa_points_select","radius","DOUBLE")
arcpy.CalculateField_management("all_wdpa_points_select","radius","math.sqrt(!REP_AREA!/math.pi )*1000","PYTHON_9.3")
arcpy.Buffer_analysis("all_wdpa_points_select","all_wdpa_points_select_buff","radius","","","","","GEODESIC")

# combine the poly selection with the buffered point selection
# the output (hereafter 'polybuffpnt') represents the starting point for the monthly release - it is all the sites we include in the analysis in one file
arcpy.Merge_management(["all_wdpa_points_select_buff","all_wdpa_polygons_select"],"all_wdpa_polybuffpnt")

# repair the polybuffpnt
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt","DELETE_NULL","OGC")

# rename the ISO3 field in the WDPA to clarify it is the WDPA ISO3 and not a basemap ISO3
arcpy.AlterField_management("all_wdpa_polybuffpnt","ISO3","WDPA_ISO3")

# split up the polybuffpnt using the Union tool - this splits up the WDPA like a Venn diagram
arcpy.Union_analysis("all_wdpa_polybuffpnt","all_wdpa_polybuffpnt_union")

# repair the output of the union
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union","DELETE_NULL","OGC")

# add xy coordinates for each of the ~1 million segments
arcpy.AddGeometryAttributes_management("all_wdpa_polybuffpnt_union","CENTROID")

# add a new field to concatenate the new x and y coordinate fields
arcpy.AddField_management("all_wdpa_polybuffpnt_union","XYco","TEXT")

# populate this new XYco field
arcpy.CalculateField_management("all_wdpa_polybuffpnt_union","XYco","str(!CENTROID_X!) + str(!CENTROID_Y!)","PYTHON_9.3")

# run a summary of the XYco field, showing how many instances there are of each XYyco, i.e. how many segments have
# exactly the same XYco, and by extension geometry.
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_union","xyco_count",[["XYco","COUNT"]],"XYco")

# join (add) the XYco field from the summary table to the output of the union
arcpy.JoinField_management("all_wdpa_polybuffpnt_union","XYco","xyco_count","XYco","COUNT_XYco")

# clean up some redundant fields
arcpy.DeleteField_management("all_wdpa_polybuffpnt_union",["BUFF_DIST","CENTROID_X","CENTROID_Y","FID_all_wdpa_polybuffpnt","OBJECTID","OBJECTID_1","ORIG_FID","radius"])

# join the xyco summary table back to the spatial data by XYco - adding the XYco COUNT field to the spatial data
#arcpy.AddJoin_management("all_wdpa_polybuffpnt_union","XYco","xyco_count","XYco","KEEP_ALL")

# select out all of the segments which only have 1 XYco, i.e. the novel geometries with no overlaps within the WDPA
arcpy.Select_analysis("all_wdpa_polybuffpnt_union","all_wdpa_polybuffpnt_union_unique","COUNT_XYco = 1")

# select out all of the segments which have >1 XYco, i.e. geometries which overlap within the WDPA
arcpy.Select_analysis("all_wdpa_polybuffpnt_union","all_wdpa_polybuffpnt_union_duplicates","COUNT_XYco > 1")

# remove the overlaps within the duplicates
arcpy.Dissolve_management("all_wdpa_polybuffpnt_union_duplicates","all_wdpa_polybuffpnt_union_duplicates_diss","XYco","STATUS_YR MIN; WDPA_ISO3 FIRST")

# repair the flattened duplicates
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union_duplicates_diss","DELETE_NULL","OGC")

# recombine the unique geometries with the flattened duplicates
arcpy.Merge_management(["all_wdpa_polybuffpnt_union_duplicates_diss", "all_wdpa_polybuffpnt_union_unique"], "all_wdpa_polybuffpnt_union_flat")

# repair the recombined layer
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union_flat","DELETE_NULL","OGC")

# intersect it with the basemap
arcpy.Intersect_analysis(["all_wdpa_polybuffpnt_union_flat",in_basemap_spat],"all_wdpa_polybuffpnt_union_flat_intersect")

# repair it
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union_flat_intersect","DELETE_NULL","OGC")

# project it into mollweide, an equal area projection
arcpy.Project_management("all_wdpa_polybuffpnt_union_flat_intersect","all_wdpa_polybuffpnt_union_flat_intersect_project",in_mollweideprj)

# repair it
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union_flat_intersect_project","DELETE_NULL","OGC")

# add and calculate a new area field
arcpy.AddGeometryAttributes_management("all_wdpa_polybuffpnt_union_flat_intersect_project","AREA_GEODESIC","","SQUARE_KILOMETERS",in_mollweideprj)

# now we get into a whole reem of summary statistics that have to created and rejigged in quite a specific way
# for the explanation and underlying rationale for these decisions please see accompanying metadata.

# run summary statistics on the layer globally
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_union_flat_intersect_project","global_summary_statistics",[["AREA_GEO","SUM"]],"type")

# run some summary stats on the layer per year for timeseries figures
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_union_flat_intersect_project","global_summary_statistics_temporal",[["AREA_GEO","SUM"]],["type","STATUS_YR"])

# pivot this temporal summary table
arcpy.PivotTable_management("global_summary_statistics_temporal","STATUS_YR","type","SUM_AREA_GEO","global_summary_statistics_temporal_pivot")

# repeat the last two steps just for ABNJ geometries
# select out just the rows with an ISO3 of 'ABNJ'
arcpy.Select_analysis("all_wdpa_polybuffpnt_union_flat_intersect_project","ABNJ_sites","WDPA_ISO3 = 'ABNJ'")

# run some summary stats on the ABNJ selection per year for timeseries figures
arcpy.Statistics_analysis("ABNJ_sites","abnj_global_summary_statistics_temporal",[["AREA_GEO","SUM"]],"STATUS_YR")

# properly combining these output tables has to be done manually in excel.
# this only takes 5 minutes and allows the user to sense check what the model has created.

elapsed_hours = (time.clock() - start)/3600
print(("Stage 1 took " + str(elapsed_hours) + " hours"))

##-------------------------------------------------------------------------------------------------------------------------
#Stage 2: National analysis

print ("Stage 2/3: National Analyses")

# this stage starts from the repaired polybuffpnt.

# split the polybuffpnt depending on whether sites occur within one country or span multiple countries
arcpy.Select_analysis("all_wdpa_polybuffpnt","all_wdpa_polybuffpnt_nontransboundary","WDPA_ISO3 NOT LIKE '%;%'")
arcpy.Select_analysis("all_wdpa_polybuffpnt","all_wdpa_polybuffpnt_transboundary","WDPA_ISO3 LIKE '%;%'")

# repair the geometries of both subsets
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_nontransboundary","DELETE_NULL","OGC")
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_transboundary","DELETE_NULL","OGC")

# flatten each subset - transboundary sites arent flattened by country as their ISO3 values span several countries and have to be assigned geographically
arcpy.Dissolve_management("all_wdpa_polybuffpnt_nontransboundary","all_wdpa_polybuffpnt_nontransboundary_diss","WDPA_ISO3")
arcpy.Dissolve_management("all_wdpa_polybuffpnt_transboundary","all_wdpa_polybuffpnt_transboundary_diss","")

# repair the geometries of both subsets
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_nontransboundary_diss","DELETE_NULL","OGC")
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_transboundary_diss","DELETE_NULL","OGC")

# erase the transboundary sites from the non-transboundary sites, identifying the novel area only they cover
arcpy.Erase_analysis("all_wdpa_polybuffpnt_transboundary_diss","all_wdpa_polybuffpnt_nontransboundary_diss","all_wdpa_polybuffpnt_transboundary_diss_novelarea")

# repair the output from the erase
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_transboundary_diss_novelarea","DELETE_NULL","OGC")

# intersect the novel area transboundary sites and the non-transboundary sites
arcpy.Intersect_analysis(["all_wdpa_polybuffpnt_transboundary_diss_novelarea",in_basemap_spat],"all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect")
arcpy.Intersect_analysis(["all_wdpa_polybuffpnt_nontransboundary_diss",in_basemap_spat],"all_wdpa_polybuffpnt_nontransboundary_diss_intersect")

# repair the intersects
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_nontransboundary_diss_intersect","DELETE_NULL","OGC")
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect","DELETE_NULL","OGC")

# add a new field, "typeISO3"
arcpy.AddField_management("all_wdpa_polybuffpnt_nontransboundary_diss_intersect","typeISO3","TEXT")
arcpy.AddField_management("all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect","typeISO3","TEXT")

# calculate typeISO3, by concatenating 'type' form the basemap with ISO3
# nontransboundary use the 'WDPA_ISO3' but transboundary use the 'GEO_ISO3' because they've been dissolved
arcpy.CalculateField_management("all_wdpa_polybuffpnt_nontransboundary_diss_intersect","typeISO3","!type! + !WDPA_ISO3!","PYTHON_9.3")
arcpy.CalculateField_management("all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect","typeISO3","!type! + !GEO_ISO3!","PYTHON_9.3")

# project both transboundary and nontransboundary features into Mollweide
arcpy.Project_management("all_wdpa_polybuffpnt_nontransboundary_diss_intersect","all_wdpa_polybuffpnt_nontransboundary_diss_intersect_project",in_mollweideprj)
arcpy.Project_management("all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect","all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect_project",in_mollweideprj)

# add and calculate a new area field
arcpy.AddGeometryAttributes_management("all_wdpa_polybuffpnt_nontransboundary_diss_intersect_project","AREA_GEODESIC","","SQUARE_KILOMETERS",in_mollweideprj)
arcpy.AddGeometryAttributes_management("all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect_project","AREA_GEODESIC","","SQUARE_KILOMETERS",in_mollweideprj)

# rename the GEO_ISO3 field in the transboundary subset back into WDPA_ISO3
arcpy.AlterField_management("all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect_project","GEO_ISO3","WDPA_ISO3","WDPA_ISO3")

# run summary statistics on each subset
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_nontransboundary_diss_intersect_project","non_transboundary_national_statistics",[["AREA_GEO","SUM"]],["type","WDPA_ISO3","typeISO3"])
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_transboundary_diss_novelarea_intersect_project","transboundary_national_statistics",[["AREA_GEO","SUM"]],["type","WDPA_ISO3","typeISO3"])

# merge the summary statistics from each subset
arcpy.Merge_management(["non_transboundary_national_statistics","transboundary_national_statistics"],"national_statistics_merge")

# join to the basemap to get fields reporting on basemap area
arcpy.JoinField_management("national_statistics_merge","typeISO3",in_basemap_spat,"GEO_typeISO3")

# run summary statistics again, now including the basemap area also
arcpy.Statistics_analysis("national_statistics_merge","national_statistics_merge_summary",[["SUM_AREA_GEO","SUM"]],["type","WDPA_ISO3","typeISO3","AREA_KM2"])

# rename the summarised PA area field
arcpy.AlterField_management("national_statistics_merge_summary","SUM_SUM_AREA_GEO","PA_AREA","PA_AREA")

# run a pivot table
arcpy.PivotTable_management("national_statistics_merge_summary","WDPA_ISO3","type","PA_AREA","national_statistics_merge_summary_pivot")

# join to a tabular version of the basemap
arcpy.JoinField_management("national_statistics_merge_summary_pivot","WDPA_ISO3",in_basemap_tab,"GEO_ISO3",["land_area", "marine_area"])

# rename several fields
arcpy.AlterField_management("national_statistics_merge_summary_pivot","WDPA_ISO3","iso3")
arcpy.AlterField_management("national_statistics_merge_summary_pivot","Land","pa_land_area")
arcpy.AlterField_management("national_statistics_merge_summary_pivot","EEZ","pa_marine_area")

# update the fields so that they have '0' values instead of empty cells
# define the codeblock:

in_codeblock = """
def updateValue(value):
  if value == None:
   return '0'
  else: return value"""

arcpy.CalculateField_management("national_statistics_merge_summary_pivot","pa_land_area","updateValue(!pa_land_area!)","PYTHON_9.3", in_codeblock)
arcpy.CalculateField_management("national_statistics_merge_summary_pivot","pa_marine_area","updateValue(!pa_marine_area!)","PYTHON_9.3", in_codeblock)
arcpy.CalculateField_management("national_statistics_merge_summary_pivot","ABNJ","updateValue(!ABNJ!)","PYTHON_9.3", in_codeblock)

# combine the ABNJ and EEZ area per country into the pa_marine_area field
arcpy.CalculateField_management("national_statistics_merge_summary_pivot","pa_marine_area","!ABNJ! + !pa_marine_area!","PYTHON_9.3")

# delete the now redudndant ABNJ field
arcpy.DeleteField_management("national_statistics_merge_summary_pivot","ABNJ")

# add the fields to calculate percentage coverage
arcpy.AddField_management("national_statistics_merge_summary_pivot","percentage_pa_land_cover","FLOAT")
arcpy.AddField_management("national_statistics_merge_summary_pivot","percentage_pa_marine_cover","FLOAT")

# calculate fields
arcpy.CalculateField_management("national_statistics_merge_summary_pivot","percentage_pa_land_cover","(!pa_land_area! / !land_area!)*100","PYTHON_9.3")
arcpy.CalculateField_management("national_statistics_merge_summary_pivot","percentage_pa_marine_cover","(!pa_marine_area! / !marine_area!)*100","PYTHON_9.3")

# Unlike global stats, the summary national stats table should be ready for import by Informatics.
# There is not an automated QC process for the stats yet however so we suggest that the table is copied into the Excel template and compared to the previous months stats etc

elapsed_hours = (time.clock() - start)/3600

print (("Stage 2 took " + str(elapsed_hours) + " hours"))
print ("almost there...")

#-----------------------------------------------------------------------------------------------------------------------
#Stage 3: National PAME analysis

print ("Stage 3/3: PAME analyses")

#This stage also starts from the repaired polybuffpnt and repeats the national analysis using only those sites that have had a PAME analysis.

# join the polybuffpnt to the PAME sites
arcpy.JoinField_management("all_wdpa_polybuffpnt","WDPAID",in_pame_sites,"wdpaid","ass_id")

# select out the sites that have had a pame assessment
arcpy.Select_analysis("all_wdpa_polybuffpnt", "all_wdpa_polybuffpnt_pamesites","ass_id >= 1")

# split the pame polybuffpnt depending on whether sites occur within one country or span multiple countries
arcpy.Select_analysis("all_wdpa_polybuffpnt_pamesites","all_wdpa_polybuffpnt_pamesites_nontransboundary","WDPA_ISO3 NOT LIKE '%;%'")
arcpy.Select_analysis("all_wdpa_polybuffpnt_pamesites","all_wdpa_polybuffpnt_pamesites_transboundary","WDPA_ISO3 LIKE '%;%'")

# repair the geometries of both subsets
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_pamesites_nontransboundary","DELETE_NULL","OGC")
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_pamesites_transboundary","DELETE_NULL","OGC")

# flatten each subset - transboundary sites arent flattened by country as their ISO3 values span several countries and have to be assigned geographically
arcpy.Dissolve_management("all_wdpa_polybuffpnt_pamesites_nontransboundary","all_wdpa_polybuffpnt_pamesites_nontransboundary_diss","WDPA_ISO3")
arcpy.Dissolve_management("all_wdpa_polybuffpnt_pamesites_transboundary","all_wdpa_polybuffpnt_pamesites_transboundary_diss","")

# repair the geometries of both subsets
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_pamesites_nontransboundary_diss","DELETE_NULL","OGC")
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_pamesites_transboundary_diss","DELETE_NULL","OGC")

# erase the transboundary sites from the non-transboundary sites, identifying the novel area only they cover
arcpy.Erase_analysis("all_wdpa_polybuffpnt_pamesites_transboundary_diss","all_wdpa_polybuffpnt_pamesites_nontransboundary_diss","all_wdpa_polybuffpnt_pamesites_transboundary_diss_novelarea")

# repair the output from the erase
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_pamesites_transboundary_diss_novelarea","DELETE_NULL","OGC")

# intersect the novel area transboundary sites and the non-transboundary sites
arcpy.Intersect_analysis(["all_wdpa_polybuffpnt_pamesites_transboundary_diss_novelarea",in_basemap_spat],"all_wdpa_polybuffpnt_pamesites_transboundary_novelarea_intersect")
arcpy.Intersect_analysis(["all_wdpa_polybuffpnt_pamesites_nontransboundary_diss",in_basemap_spat],"all_wdpa_polybuffpnt_pamesites_nontransboundary_diss_intersect")

# repair the intersects
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_pamesites_nontransboundary_diss_intersect","DELETE_NULL","OGC")
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_pamesites_transboundary_novelarea_intersect","DELETE_NULL","OGC")

# add a new field, "typeISO3"
arcpy.AddField_management("all_wdpa_polybuffpnt_pamesites_nontransboundary_diss_intersect","typeISO3","TEXT")
arcpy.AddField_management("all_wdpa_polybuffpnt_pamesites_transboundary_novelarea_intersect","typeISO3","TEXT")

# calculate typeISO3, by concatenating 'type' form the basemap with ISO3
# nontransboundary use the 'WDPA_ISO3' but transboundary use the 'GEO_ISO3' because they've been dissolved
arcpy.CalculateField_management("all_wdpa_polybuffpnt_pamesites_nontransboundary_diss_intersect","typeISO3","!type! + !WDPA_ISO3!","PYTHON_9.3")
arcpy.CalculateField_management("all_wdpa_polybuffpnt_pamesites_transboundary_novelarea_intersect","typeISO3","!type! + !GEO_ISO3!","PYTHON_9.3")

# project both transboundary and nontransboundary features into Mollweide
arcpy.Project_management("all_wdpa_polybuffpnt_pamesites_nontransboundary_diss_intersect","all_wdpa_polybuffpnt_pamesites_nontransboundary_diss_intersect_project",in_mollweideprj)
arcpy.Project_management("all_wdpa_polybuffpnt_pamesites_transboundary_novelarea_intersect","all_wdpa_polybuffpnt_pamesites_transboundary_diss_novelarea_intersect_project",in_mollweideprj)

# add and calculate a new area field
arcpy.AddGeometryAttributes_management("all_wdpa_polybuffpnt_pamesites_nontransboundary_diss_intersect_project","AREA_GEODESIC","","SQUARE_KILOMETERS",in_mollweideprj)
arcpy.AddGeometryAttributes_management("all_wdpa_polybuffpnt_pamesites_transboundary_diss_novelarea_intersect_project","AREA_GEODESIC","","SQUARE_KILOMETERS",in_mollweideprj)

# rename the GEO_ISO3 field in the transboundary subset back into WDPA_ISO3
arcpy.AlterField_management("all_wdpa_polybuffpnt_pamesites_transboundary_diss_novelarea_intersect_project","GEO_ISO3","WDPA_ISO3","WDPA_ISO3")

# run summary statistics on each subset
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_pamesites_nontransboundary_diss_intersect_project","pame_non_transboundary_national_statistics",[["AREA_GEO","SUM"]],["type","WDPA_ISO3","typeISO3"])
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_pamesites_transboundary_diss_novelarea_intersect_project","pame_transboundary_national_statistics",[["AREA_GEO","SUM"]],["type","WDPA_ISO3","typeISO3"])

# merge the summary statistics from each subset
arcpy.Merge_management(["pame_non_transboundary_national_statistics","pame_transboundary_national_statistics"],"pame_national_statistics_merge")

# join to the basemap to get fields reporting on basemap area
arcpy.JoinField_management("pame_national_statistics_merge","typeISO3",in_basemap_spat,"GEO_typeISO3")

# run summary statistics again, now including the basemap area also
arcpy.Statistics_analysis("pame_national_statistics_merge","pame_national_statistics_merge_summary",[["SUM_AREA_GEO","SUM"]],["type","WDPA_ISO3","typeISO3","AREA_KM2"])

# rename the summarised PA area field
arcpy.AlterField_management("pame_national_statistics_merge_summary","SUM_SUM_AREA_GEO","PA_AREA","PA_AREA")

# run a pivot table
arcpy.PivotTable_management("pame_national_statistics_merge_summary","WDPA_ISO3","type","PA_AREA","pame_national_statistics_merge_summary_pivot")

# join to a tabular version of the basemap
arcpy.JoinField_management("pame_national_statistics_merge_summary_pivot","WDPA_ISO3",in_basemap_tab,"GEO_ISO3",["land_area", "marine_area"])

# rename several fields
arcpy.AlterField_management("pame_national_statistics_merge_summary_pivot","WDPA_ISO3","iso3")
arcpy.AlterField_management("pame_national_statistics_merge_summary_pivot","Land","pame_pa_land_area")
arcpy.AlterField_management("pame_national_statistics_merge_summary_pivot","EEZ","pame_pa_marine_area")

# update the fields so that they have '0' values instead of empty cells
arcpy.CalculateField_management("pame_national_statistics_merge_summary_pivot","pame_pa_land_area","updateValue(!pame_pa_land_area!)","PYTHON_9.3", in_codeblock)
arcpy.CalculateField_management("pame_national_statistics_merge_summary_pivot","pame_pa_marine_area","updateValue(!pame_pa_marine_area!)","PYTHON_9.3", in_codeblock)
arcpy.CalculateField_management("pame_national_statistics_merge_summary_pivot","ABNJ","updateValue(!ABNJ!)","PYTHON_9.3", in_codeblock)

# combine the ABNJ and EEZ area per country into the pa_marine_area field
arcpy.CalculateField_management("pame_national_statistics_merge_summary_pivot","pame_pa_marine_area","!ABNJ! + !pame_pa_marine_area!","PYTHON_9.3")

# delete the now redudndant ABNJ field
arcpy.DeleteField_management("pame_national_statistics_merge_summary_pivot","ABNJ")

# add the fields to calculate percentage coverage
arcpy.AddField_management("pame_national_statistics_merge_summary_pivot","pame_percentage_pa_land_cover","FLOAT")
arcpy.AddField_management("pame_national_statistics_merge_summary_pivot","pame_percentage_pa_marine_cover","FLOAT")

# join the final national stats with the pame national stats
arcpy.JoinField_management("national_statistics_merge_summary_pivot","iso3","pame_national_statistics_merge_summary_pivot","iso3",["pame_pa_marine_area","pame_pa_land_area","pame_percentage_pa_land_cover","pame_percentage_pa_marine_cover"])

# calculate fields
arcpy.CalculateField_management("pame_national_statistics_merge_summary_pivot","pame_percentage_pa_land_cover","(!pame_pa_land_area! / !land_area!)*100","PYTHON_9.3")
arcpy.CalculateField_management("pame_national_statistics_merge_summary_pivot","pame_percentage_pa_marine_cover","(!pame_pa_marine_area! / !marine_area!)*100","PYTHON_9.3")

elapsed_hours = (time.clock() - start)/3600

print ("scripts finished - all good")
print ("Outputs are here: " + workspace)
print ("Total running time: " + str(elapsed_hours) + " hours")

# Finish running scripts
#----------------------------------------------------------------------------------------------------------------------
